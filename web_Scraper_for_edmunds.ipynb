{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 48,
            "source": [
                "import os\r\n",
                "from urllib.request import Request, urlopen\r\n",
                "from urllib.error import URLError\r\n",
                "import requests, wget, re\r\n",
                "from time import sleep\r\n",
                "import configuration as config\r\n",
                "from pathlib import Path\r\n",
                "\r\n",
                "from random_user_agent.user_agent import UserAgent\r\n",
                "from random_user_agent.params import SoftwareName, OperatingSystem\r\n",
                "\r\n",
                "# you can also import SoftwareEngine, HardwareType, SoftwareType, Popularity from random_user_agent.params\r\n",
                "# you can also set number of user agents required by providing `limit` as parameter\r\n",
                "\r\n",
                "software_names = [SoftwareName.CHROME.value]\r\n",
                "operating_systems = [OperatingSystem.WINDOWS.value, OperatingSystem.LINUX.value]   \r\n",
                "\r\n",
                "user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=100)\r\n",
                "\r\n",
                "# Get list of user agents.\r\n",
                "user_agents = user_agent_rotator.get_user_agents()\r\n",
                "\r\n",
                "# Get Random User Agent String.\r\n",
                "user_agent = user_agent_rotator.get_random_user_agent()\r\n",
                "#print(user_agent)"
            ],
            "outputs": [],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 49,
            "source": [
                "webpage_dict = {}\r\n",
                "url_list = []\r\n",
                "\r\n",
                "download=False\r\n",
                "i=0 \r\n",
                "#get search urls / kbb only? \r\n",
                "with open(join(config.INPUT_DIR, 'url_list.txt'), 'r') as f:\r\n",
                "    search_url_list = f.readlines()\r\n",
                "\r\n",
                "#find urls in a kbb search page\r\n",
                "for search_url in search_url_list:\r\n",
                "    txt = requests.get(search_url).text\r\n",
                "    found_urls = re.findall(r'\"url\":(\".*?\")', txt)\r\n",
                "\r\n",
                "    for item in found_urls:\r\n",
                "        if 'listingId' not in item:\r\n",
                "            found_urls.remove(item)\r\n",
                "        if len(item) < 10:\r\n",
                "            found_urls.remove(item)\r\n",
                "    url_list.extend(found_urls[:-4])\r\n",
                "\r\n",
                "\r\n",
                "for url in url_list:\r\n",
                "    print(i, end=\" \")\r\n",
                "    i+=1\r\n",
                "    try:\r\n",
                "        url = url.split('\"')[1]\r\n",
                "    except:\r\n",
                "        pass\r\n",
                "    req = Request(url, headers={'User-Agent':user_agent_rotator.get_random_user_agent(),\r\n",
                "                                'accept':'text/html;q=0.8,application/signed-exchange;v=b3;q=0.9',\r\n",
                "                                'accept-language':'en-US,en;q=0.9'})\r\n",
                "    try:\r\n",
                "        response = urlopen(req)\r\n",
                "    except URLError as e:\r\n",
                "        print(url)\r\n",
                "        if hasattr(e, 'reason'):\r\n",
                "            print('We failed to reach a server.')\r\n",
                "            print('Reason: ', e.reason)\r\n",
                "        elif hasattr(e, 'code'):\r\n",
                "            print('The server couldn\\'t fulfill the request')\r\n",
                "            print('Error code:', e.code)\r\n",
                "    else:\r\n",
                "        try:\r\n",
                "            if response.headers.get_content_charset() == 'utf-8':\r\n",
                "                webpage_as_string = response.read().decode(response.headers.get_content_charset(), \"ignore\")\r\n",
                "            else:\r\n",
                "                webpage_as_string = response.read().decode(response.headers.get_content_charset(), \"ignore\")\r\n",
                "        except UnicodeEncodeError as e:\r\n",
                "            print(e)\r\n",
                "            webpage_as_string = response.read()\r\n",
                "        #print(webpage_as_string)\r\n",
                "        #print(response.headers.get_content_charset())\r\n",
                "        \r\n",
                "        if download == True:\r\n",
                "            filename = url.split('//')[1].split('/')[0]\r\n",
                "            with open(filename+'.txt', 'wb') as f:\r\n",
                "                f.write(webpage_as_string.encode('ascii', 'ignore'))\r\n",
                "                \r\n",
                "        webpage_dict[url] = (webpage_as_string)"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 https://www.kbb.com/cars-for-sale/vehicledetails.xhtml?listingId=592771169\n",
                        "We failed to reach a server.\n",
                        "Reason:  Forbidden\n",
                        "46 47 48 49 50 51 52 53 "
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": 52,
            "source": [
                "import requests\r\n",
                "import json\r\n",
                "from ast import literal_eval\r\n",
                "import pandas as pd\r\n",
                "from os.path import join\r\n",
                "\r\n",
                "output_filename = join(config.OUTPUT_DIR, f\"potential vehicles.csv\")\r\n",
                "vehicle_df = pd.DataFrame(columns=[\"Price\", \"Mileage\", \"Year\", \"Make\", \"Model\", \"Trim\", \r\n",
                "                            \"Color\", \"Fuel Economy\", \"VIN\", \"Location\", \"URL\"])\r\n",
                "\r\n",
                "if os.path.exists(output_filename):\r\n",
                "    vehicle_df = pd.read_csv(output_filename)\r\n",
                "\r\n",
                "for url, txt in webpage_dict.items():\r\n",
                "    #print(url)\r\n",
                "    with open(\"debug.txt\", \"w\") as f: f.write(txt)\r\n",
                "    base_url = '/'.join(url.split('/')[0:3])\r\n",
                "\r\n",
                "        #kbb data scraper\r\n",
                "    if 'kbb' in base_url:  \r\n",
                "            #find vehicle data\r\n",
                "        vehicle_dict = {}\r\n",
                "        url = url.split(\"&\")[0]\r\n",
                "        try:\r\n",
                "            location_dict = literal_eval(re.findall(r'\"location\":({.*?})', txt)[1]+\"}\")['address']\r\n",
                "            vehicle_data_dict = literal_eval(re.findall(r'\"vehicle\":({.*?})', txt)[0])\r\n",
                "        except:\r\n",
                "            continue\r\n",
                "\r\n",
                "            #put vehicle data into dict\r\n",
                "        #address = location_dict['address1']\r\n",
                "        city = location_dict['city']\r\n",
                "        state = location_dict['state']\r\n",
                "        zip_code = location_dict['zip']\r\n",
                "\r\n",
                "        full_address = f\"{city}, {state} {zip_code}\"\r\n",
                "            \r\n",
                "        vehicle_dict[\"Price\"] = vehicle_data_dict['price']\r\n",
                "        vehicle_dict[\"Mileage\"] = int(\"\".join(vehicle_data_dict['odometer'].split(',')).split(\" \")[0])\r\n",
                "        vehicle_dict[\"Year\"] = vehicle_data_dict['car_year']\r\n",
                "        vehicle_dict[\"Make\"] = vehicle_data_dict['makeName'][0]\r\n",
                "        vehicle_dict[\"Model\"] = vehicle_data_dict['modelName'][0]\r\n",
                "        vehicle_dict[\"Color\"] = vehicle_data_dict['color'][0]\r\n",
                "        vehicle_dict[\"Fuel Economy\"] = \" | \".join(vehicle_data_dict['fuelEconomy'])\r\n",
                "        vehicle_dict[\"VIN\"] = vehicle_data_dict['vin']\r\n",
                "        vehicle_dict[\"Location\"] = full_address\r\n",
                "        vehicle_dict[\"URL\"] = url\r\n",
                "        \r\n",
                "        try:\r\n",
                "            vehicle_dict[\"Trim\"] = vehicle_data_dict['trim']\r\n",
                "        except:\r\n",
                "            pass\r\n",
                "\r\n",
                "        vehicle_df = vehicle_df.append(vehicle_dict, ignore_index=True)\r\n",
                "\r\n",
                "    #add vehicle_dict to dataframe and save in csv\r\n",
                "    elif 'dat boi' in base_url:\r\n",
                "        pass\r\n",
                "\r\n",
                "vehicle_df = vehicle_df.drop_duplicates()\r\n",
                "print(len(vehicle_df))\r\n",
                "vehicle_df.to_csv(join(output_filename), index=False)\r\n"
            ],
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": [
                        "61\n"
                    ]
                }
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "source": [
                "\r\n",
                "\r\n"
            ],
            "outputs": [],
            "metadata": {}
        }
    ],
    "metadata": {
        "orig_nbformat": 4,
        "language_info": {
            "name": "python",
            "version": "3.9.1",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3.9.1 64-bit"
        },
        "interpreter": {
            "hash": "764ba89bf3c2408fcaa76b3d6f4b48249f73fb696a8c206ed5bda6c76d9498eb"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}